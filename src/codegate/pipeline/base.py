import dataclasses
import datetime
import json
import uuid
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Dict, List, Optional

import structlog
from litellm import ChatCompletionRequest

from codegate.db.models import Alert
from codegate.pipeline.secrets.manager import SecretsManager

logger = structlog.get_logger("codegate")


@dataclass
class CodeSnippet:
    """
    Represents a code snippet with its programming language.

    Args:
        language: The programming language identifier (e.g., 'python', 'javascript')
        code: The actual code content
    """

    code: str
    language: Optional[str]
    filepath: Optional[str]
    libraries: List[str] = field(default_factory=list)

    def __post_init__(self):
        if self.language is not None:
            self.language = self.language.strip().lower()


class AlertSeverity(Enum):
    INFO = "info"
    CRITICAL = "critical"


@dataclass
class PipelineSensitiveData:
    manager: SecretsManager
    session_id: str
    api_key: Optional[str] = None
    model: Optional[str] = None
    provider: Optional[str] = None
    api_base: Optional[str] = None

    def secure_cleanup(self):
        """Securely cleanup sensitive data for this session"""
        if self.manager is None or self.session_id == "":
            return

        self.manager.cleanup_session(self.session_id)
        self.session_id = ""

        # Securely wipe the API key using the same method as secrets manager
        if self.api_key is not None:
            api_key_bytes = bytearray(self.api_key.encode())
            self.manager.crypto.wipe_bytearray(api_key_bytes)
            self.api_key = None

        self.model = None


@dataclass
class PipelineContext:
    code_snippets: List[CodeSnippet] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    sensitive: Optional[PipelineSensitiveData] = field(default_factory=lambda: None)
    alerts_raised: List[Alert] = field(default_factory=list)

    def add_code_snippet(self, snippet: CodeSnippet):
        self.code_snippets.append(snippet)

    def get_snippets_by_language(self, language: str) -> List[CodeSnippet]:
        return [s for s in self.code_snippets if s.language.lower() == language.lower()]

    def add_alert(
        self,
        step_name: str,
        severity_category: AlertSeverity = AlertSeverity.INFO,
        code_snippet: Optional[CodeSnippet] = None,
        trigger_string: Optional[str] = None,
    ) -> None:
        """
        Add an alert to the pipeline step alerts_raised.
        """
        if not self.metadata.get("prompt_id"):
            logger.warning("No prompt_id found in context. Alert will not be created")
            return

        if not code_snippet and not trigger_string:
            logger.warning("No code snippet or trigger string provided for alert. Will not create")
            return

        code_snippet_str = json.dumps(dataclasses.asdict(code_snippet)) if code_snippet else None

        self.alerts_raised.append(
            Alert(
                id=str(uuid.uuid4()),
                prompt_id=self.metadata["prompt_id"],
                code_snippet=code_snippet_str,
                trigger_string=trigger_string,
                trigger_type=step_name,
                trigger_category=severity_category.value,
                timestamp=datetime.datetime.now(datetime.timezone.utc),
            )
        )


@dataclass
class PipelineResponse:
    """Response generated by a pipeline step"""

    content: str
    step_name: str  # The name of the pipeline step that generated this response
    model: str  # Taken from the original request's model field


@dataclass
class PipelineResult:
    """
    Represents the result of a pipeline operation.
    Either contains a modified request to continue processing,
    or a response to return to the client.
    """

    request: Optional[ChatCompletionRequest] = None
    response: Optional[PipelineResponse] = None
    context: Optional[PipelineContext] = None
    error_message: Optional[str] = None

    def shortcuts_processing(self) -> bool:
        """Returns True if this result should end pipeline processing"""
        return self.response is not None or self.error_message is not None

    @property
    def success(self) -> bool:
        """Returns True if the pipeline step completed without errors"""
        return self.error_message is None


class PipelineStep(ABC):
    """Base class for all pipeline steps in the processing chain."""

    @property
    @abstractmethod
    def name(self) -> str:
        """
        Returns the name of the pipeline step.

        Returns:
            str: A unique identifier for this pipeline step
        """
        pass

    @staticmethod
    def get_last_user_message(
        request: ChatCompletionRequest,
    ) -> Optional[tuple[str, int]]:
        """
        Get the last user message and its index from the request.

        Args:
            request (ChatCompletionRequest): The chat completion request to process

        Returns:
            Optional[tuple[str, int]]: A tuple containing the message content and
                                       its index, or None if no user message is found
        """
        if request.get("messages") is None:
            return None
        for i in reversed(range(len(request["messages"]))):
            if request["messages"][i]["role"] == "user":
                content = request["messages"][i]["content"]

                # This is really another LiteLLM weirdness. Depending on the
                # provider inside the ChatCompletionRequest you might either
                # have a string or a list of Union, one of which is a
                # ChatCompletionTextObject. We'll handle this better by
                # either dumping litellm completely or converting to a more sane
                # format # in our own adapter

                # Handle string content
                if isinstance(content, str):
                    return content, i

                # Handle iterable of ChatCompletionTextObject
                if isinstance(content, (list, tuple)):
                    # Find first text content
                    for item in content:
                        if isinstance(item, dict) and item.get("type") == "text":
                            return item["text"], i

                    # If no text content found, return None
                    return None

        return None

    @abstractmethod
    async def process(
        self, request: ChatCompletionRequest, context: PipelineContext
    ) -> PipelineResult:
        """Process a request and return either modified request or response stream"""
        pass


class InputPipelineInstance:
    def __init__(self, pipeline_steps: List[PipelineStep], secret_manager: SecretsManager):
        self.pipeline_steps = pipeline_steps
        self.secret_manager = secret_manager
        self.context = PipelineContext()

    async def process_request(
        self,
        request: ChatCompletionRequest,
        provider: str,
        prompt_id: str,
        model: str,
        api_key: Optional[str] = None,
        api_base: Optional[str] = None,
        extra_headers: Optional[Dict[str, str]] = None,
    ) -> PipelineResult:
        """Process a request through all pipeline steps"""
        self.context.sensitive = PipelineSensitiveData(
            manager=self.secret_manager,
            session_id=str(uuid.uuid4()),
            api_key=api_key,
            model=model,
            provider=provider,
            api_base=api_base,
        )
        self.context.metadata["prompt_id"] = prompt_id
        self.context.metadata["extra_headers"] = extra_headers
        current_request = request

        for step in self.pipeline_steps:
            result = await step.process(current_request, self.context)
            if result is None:
                continue

            if result.shortcuts_processing():
                return result

            if result.request is not None:
                current_request = result.request

            if result.context is not None:
                self.context = result.context

        return PipelineResult(request=current_request, context=self.context)


class SequentialPipelineProcessor:
    def __init__(self, pipeline_steps: List[PipelineStep], secret_manager: SecretsManager):
        self.pipeline_steps = pipeline_steps
        self.secret_manager = secret_manager

    def create_instance(self) -> InputPipelineInstance:
        """Create a new pipeline instance for processing a request"""
        return InputPipelineInstance(self.pipeline_steps, self.secret_manager)

    async def process_request(
        self,
        request: ChatCompletionRequest,
        provider: str,
        prompt_id: str,
        model: str,
        api_key: Optional[str] = None,
        api_base: Optional[str] = None,
        extra_headers: Optional[Dict[str, str]] = None,
    ) -> PipelineResult:
        """Create a new pipeline instance and process the request"""
        instance = self.create_instance()
        return await instance.process_request(
            request, provider, prompt_id, model, api_key, api_base, extra_headers
        )
